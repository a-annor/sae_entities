Loading rhel8/default-amp
  Loading requirement: rhel8/slurm singularity/current rhel8/global cuda/11.4
    libpciaccess/0.16/gcc-9.4.0-6fonbj6 libiconv/1.16/gcc-9.4.0-ahebbov
    libxml2/2.9.12/gcc-9.4.0-gnknt5e ncurses/6.2/gcc-9.4.0-aiirok7
    hwloc/2.5.0/gcc-9.4.0-7sqomga libevent/2.1.12/gcc-9.4.0-hgny7cm
    numactl/2.0.14/gcc-9.4.0-52dwc6n cuda/11.4.0/gcc-9.4.0-3hnxhjt
    gdrcopy/2.2/gcc-9.4.0-e4igtfp knem/1.1.4/gcc-9.4.0-bpbxgva
    libnl/3.3.0/gcc-9.4.0-whwhrwb rdma-core/34.0/gcc-9.4.0-5eo5n2u
    ucx/1.11.1/gcc-9.4.0-lktqyl4 openmpi/4.1.1/gcc-9.4.0-epagguv
/var/spool/slurm/slurmd/job10001357/slurm_script: line 65: conda: command not found
Setting process seed: 43
!! Loading model: google/gemma-2-2b
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:42<01:25, 42.88s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:25<00:42, 42.84s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:29<00:00, 25.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:29<00:00, 29.95s/it]
Traceback (most recent call last):
  File "/rds/user/ana42/hpc-work/sae_entities/llm_as_optim_test.py", line 277, in <module>
    main(args)
  File "/rds/user/ana42/hpc-work/sae_entities/llm_as_optim_test.py", line 202, in main
    model_gemma2_pt = model_gemma2_pt.to(args_gemma2_pt.device)  # move to device
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/rds/user/ana42/hpc-work/sae_entities/.venv/lib64/python3.11/site-packages/transformers/modeling_utils.py", line 3850, in to
    return super().to(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/rds/user/ana42/hpc-work/sae_entities/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py", line 1340, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/rds/user/ana42/hpc-work/sae_entities/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py", line 900, in _apply
    module._apply(fn)
  File "/rds/user/ana42/hpc-work/sae_entities/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py", line 900, in _apply
    module._apply(fn)
  File "/rds/user/ana42/hpc-work/sae_entities/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py", line 927, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/rds/user/ana42/hpc-work/sae_entities/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py", line 1326, in convert
    return t.to(
           ^^^^^
  File "/rds/user/ana42/hpc-work/sae_entities/.venv/lib64/python3.11/site-packages/torch/cuda/__init__.py", line 319, in _lazy_init
    torch._C._cuda_init()
RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 805: MPS client failed to connect to the MPS control daemon or the MPS server
Changed directory to /rds/user/ana42/hpc-work/sae_entities.

JobID: 10001357
======
Time: Tue May 27 21:34:59 BST 2025
Running on master node: gpu-q-9
Current directory: /rds/user/ana42/hpc-work/sae_entities

Nodes allocated:
================
gpu-q-9

numtasks=1, numnodes=1, mpi_tasks_per_node=1 (OMP_NUM_THREADS=1)

Executing command:
==================
python -u llm_as_optim_test.py  > logs/out.10001357

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.10s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.11s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.53it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
  0%|          | 0/6 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
/rds/user/ana42/hpc-work/sae_entities/.venv/lib64/python3.11/site-packages/torch/_inductor/compile_fx.py:167: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
 17%|█▋        | 1/6 [02:57<14:47, 177.50s/it] 33%|███▎      | 2/6 [03:24<05:55, 88.99s/it]  50%|█████     | 3/6 [03:51<03:02, 60.71s/it] 67%|██████▋   | 4/6 [04:53<02:02, 61.14s/it] 83%|████████▎ | 5/6 [05:19<00:48, 48.63s/it]100%|██████████| 6/6 [05:22<00:00, 32.88s/it]100%|██████████| 6/6 [05:22<00:00, 53.69s/it]
